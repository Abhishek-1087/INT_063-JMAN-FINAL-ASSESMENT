{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2de24bd-5afe-49af-8209-0ed4bc6f4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd975a37-f7b3-44e1-9c42-c5c258ee9835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snowflake-connector-python in c:\\users\\sak29\\appdata\\roaming\\python\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\sak29\\appdata\\roaming\\python\\python311\\site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (1.15.1)\n",
      "Requirement already satisfied: cryptography<43.0.0,>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (41.0.3)\n",
      "Requirement already satisfied: pyOpenSSL<25.0.0,>=16.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (23.2.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.31.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2023.7.22)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (4.7.1)\n",
      "Requirement already satisfied: filelock<4,>=3.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.9.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (3.10.0)\n",
      "Requirement already satisfied: tomlkit in c:\\programdata\\anaconda3\\lib\\site-packages (from snowflake-connector-python) (0.11.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0->snowflake-connector-python) (1.26.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254bd740-0390-4009-8362-84484b29a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pymongo\n",
    "import snowflake.connector\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5317419c-885f-4c02-92c6-974613623fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e451a7c-c468-46d6-bcf6-ac72e040c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string =  \"mongodb+srv://Abhishek_Kumar:abhi1234@cluster0.ssobpns.mongodb.net/JMAN?retryWrites=true&w=majority&appName=Cluster0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be05bb1-315b-4056-b711-3390b5226e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB Atlas successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['Project'] = 'JMAN'\n",
    "\n",
    "try:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "    mongo_db = mongo_client[os.environ['Project']]\n",
    "    \n",
    "    # Print connection success message\n",
    "    print(\"Connected to MongoDB Atlas successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with mongo_client and mongo_db\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to MongoDB Atlas: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0681717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Connect to Snowflake using environment variables\n",
    "    snowflake_conn = snowflake.connector.connect(\n",
    "        user=\"ABHISHEK\",\n",
    "        password=\"Abhi@1234\",\n",
    "        account=\"sl62884.central-india.azure\",\n",
    "        warehouse=\"COMPUTE_WH\",\n",
    "        database=\"JMAN_ASSESSMENT\",\n",
    "        schema=\"JMAN\",\n",
    "        role = \"ACCOUNTADMIN\"\n",
    "    )\n",
    "\n",
    "    # Print connection success message\n",
    "    print(\"Connected to Snowflake successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with snowflake_conn\n",
    "except snowflake.connector.errors.DatabaseError as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to Snowflake: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adbfaa6a-1de5-4d81-ac0f-9a60c0463be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved for table 'COUNT_APPROVED_SKILLS'\n",
      "CSV file saved for table 'GET_APPROVED_CERTIFICATE'\n",
      "CSV file saved for table 'REGISTERED_USER'\n",
      "CSV file saved for table 'STG_EVENTS'\n",
      "CSV file saved for table 'USERINFOS'\n",
      "CSV file saved for table 'USEREVENTS'\n",
      "CSV file saved for table 'AVERAGE_SKILLS'\n",
      "CSV file saved for table 'CERTIFICATEDETAILS'\n",
      "CSV file saved for table 'EVENTS'\n",
      "CSV file saved for table 'STG_USEREVENT'\n",
      "CSV file saved for table 'EMPLOYEE_SKILLS'\n",
      "CSV file saved for table 'STG_SKILLSDETAILS'\n",
      "CSV file saved for table 'REQUIRE_TRAINNIG'\n",
      "CSV file saved for table 'SKILLSDETAILS'\n",
      "CSV file saved for table 'STG_CERTIFICATEDETAILS'\n",
      "CSV file saved for table 'STG_USERINFOS'\n"
     ]
    }
   ],
   "source": [
    "import snowflake.connector\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Set up connection parameters\n",
    "account = 'sl62884.central-india.azure'\n",
    "user = 'ABHISHEK'\n",
    "password = 'Abhi@1234'\n",
    "warehouse = 'COMPUTE_WH'\n",
    "database = 'JMAN_ASSESSMENT'\n",
    "schema = 'JMAN'\n",
    "\n",
    "# Establish connection\n",
    "conn = snowflake.connector.connect(\n",
    "    user=user,\n",
    "    password=password,\n",
    "    account=account,\n",
    "    warehouse=warehouse,\n",
    "    database=database,\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute a query to retrieve all tables in the schema\n",
    "cur.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = %s\n",
    "\"\"\", (schema,))\n",
    "\n",
    "# Fetch all the table names\n",
    "tables = cur.fetchall()\n",
    "\n",
    "# Create a directory to save CSV files if it doesn't exist\n",
    "output_dir = 'output_csv'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each table\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    # Execute a query to fetch all data from the table\n",
    "    cur.execute(f\"SELECT * FROM {schema}.{table_name}\")\n",
    "    # Fetch all the rows\n",
    "    rows = cur.fetchall()\n",
    "    # Define the CSV file path\n",
    "    csv_file_path = os.path.join(output_dir, f\"{table_name}.csv\")\n",
    "    # Write data to CSV file\n",
    "    with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file)\n",
    "        # Write header\n",
    "        csv_writer.writerow([desc[0] for desc in cur.description])\n",
    "        # Write data rows\n",
    "        csv_writer.writerows(rows)\n",
    "    print(f\"CSV file saved for table '{table_name}'\")\n",
    "\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb50e6f9-da21-4151-9182-9a39c8949264",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snowflake_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Connect to MongoDB Atlas\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     mongo_client \u001b[38;5;241m=\u001b[39m pymongo\u001b[38;5;241m.\u001b[39mMongoClient(mongo_connection_string)\n\u001b[1;32m----> 6\u001b[0m     mongo_db \u001b[38;5;241m=\u001b[39m snowflake_client[os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Print connection success message\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected to MongoDB Atlas successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'snowflake_client' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['Project'] = 'JMAN'\n",
    "try:\n",
    "    # Connect to MongoDB Atlas\n",
    "    mongo_client = pymongo.MongoClient(mongo_connection_string)\n",
    "    mongo_db = snowflake_client[os.environ['Project']]\n",
    "    \n",
    "    # Print connection success message\n",
    "    print(\"Connected to MongoDB Atlas successfully!\")\n",
    "\n",
    "    # Now, you can perform further operations with mongo_client and mongo_db\n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    # Print connection failure message\n",
    "    print(f\"Failed to connect to MongoDB Atlas: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93decfc1-36a7-44a6-8871-0c9e0b870ba4",
   "metadata": {},
   "source": [
    "## Mongo to Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f9243c-5d60-44c4-ab1f-21b25ba0ff8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from collection 'events' written to 'staging_raw_data2/events.csv'\n",
      "Data from collection 'SkillsDetails' written to 'staging_raw_data2/SkillsDetails.csv'\n",
      "Data from collection 'CertificateDetails' written to 'staging_raw_data2/CertificateDetails.csv'\n",
      "Data from collection 'userevents' written to 'staging_raw_data2/userevents.csv'\n",
      "Data from collection 'userinfos' written to 'staging_raw_data2/userinfos.csv'\n",
      "Data from collection 'ProjectDetails' written to 'staging_raw_data2/ProjectDetails.csv'\n"
     ]
    }
   ],
   "source": [
    "# Create raw_data folder if it doesn't exist\n",
    "if not os.path.exists(\"staging_raw_data2\"):\n",
    "    os.makedirs(\"staging_raw_data2\")\n",
    "\n",
    "# Iterate over each collection\n",
    "for collection_name in mongo_db.list_collection_names():\n",
    "    # Retrieve data from collection\n",
    "    collection_data = list(mongo_db[collection_name].find())\n",
    "    \n",
    "    # Convert data to DataFrame\n",
    "    df = pd.DataFrame(collection_data)\n",
    "    \n",
    "    # Write DataFrame to CSV file\n",
    "    csv_file_path = f\"staging_raw_data2/{collection_name}.csv\"\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"Data from collection '{collection_name}' written to '{csv_file_path}'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ad9de4-c0f8-45c2-b93b-feae27a242ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close MongoDB connection\n",
    "mongo_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ae2bd-ae40-4d2a-a178-7ad079540d27",
   "metadata": {},
   "source": [
    "## Ingest Into Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4fbebe-df97-491f-a165-cb6b47dae705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from 'CertificateDetails.csv' inserted into 'CertificateDetails' table in Snowflake.\n",
      "Data from 'events.csv' inserted into 'events' table in Snowflake.\n",
      "Data from 'ProjectDetails.csv' inserted into 'ProjectDetails' table in Snowflake.\n",
      "Data from 'SkillsDetails.csv' inserted into 'SkillsDetails' table in Snowflake.\n",
      "Data from 'userevents.csv' inserted into 'userevents' table in Snowflake.\n",
      "Data from 'userinfos.csv' inserted into 'userinfos' table in Snowflake.\n"
     ]
    }
   ],
   "source": [
    "def sanitize_name(name):\n",
    "    # Replace invalid characters with underscores\n",
    "    return ''.join(c if c.isalnum() else '_' for c in name)\n",
    "if not os.path.exists(\"staging_raw_data2\"):\n",
    "    print(\"No data to process. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Iterate over each CSV file in the staging_raw_data folder\n",
    "for filename in os.listdir(\"staging_raw_data2\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Extract table name from filename (remove .csv extension) and sanitize it\n",
    "        table_name = sanitize_name(os.path.splitext(filename)[0])\n",
    "        \n",
    "        # Read CSV file into DataFrame\n",
    "        df = pd.read_csv(f\"staging_raw_data2/{filename}\")\n",
    "        \n",
    "        # Replace NaN values with empty strings\n",
    "      \n",
    "        # Convert all data to string\n",
    "        df = df.astype(str)\n",
    "        \n",
    "        # Create table in Snowflake if it doesn't exist\n",
    "        snowflake_cursor = snowflake_conn.cursor()\n",
    "        \n",
    "        # Drop the table if it exists\n",
    "        snowflake_cursor.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "        \n",
    "        # Create the table\n",
    "        create_table_query = f\"CREATE TABLE {table_name} (\"\n",
    "        for column in df.columns:\n",
    "            # Sanitize column names\n",
    "            safe_column_name = sanitize_name(column)\n",
    "            create_table_query += f'{safe_column_name} VARCHAR,'\n",
    "        create_table_query = create_table_query[:-1] + \")\"  # Remove trailing comma\n",
    "        snowflake_cursor.execute(create_table_query)\n",
    "        \n",
    "        # Prepare INSERT INTO statement\n",
    "        insert_query = f\"INSERT INTO {table_name} VALUES ({','.join(['%s'] * len(df.columns))})\"\n",
    "        \n",
    "        # Convert DataFrame to list of tuples (rows)\n",
    "        rows = [tuple(row) for row in df.itertuples(index=False)]\n",
    "        \n",
    "        # Execute bulk insert\n",
    "        snowflake_cursor.executemany(insert_query, rows)\n",
    "        snowflake_cursor.close()\n",
    "        \n",
    "        print(f\"Data from '{filename}' inserted into '{table_name}' table in Snowflake.\")\n",
    "\n",
    "# Commit the transaction\n",
    "snowflake_conn.commit()\n",
    "\n",
    "# Close Snowflake connection\n",
    "snowflake_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7a72a-1a83-4199-9ec5-9f8a68dfac9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e9785-9b49-434e-8096-9cb47e5f76e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
